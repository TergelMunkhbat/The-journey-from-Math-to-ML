{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "211f9c01",
   "metadata": {},
   "source": [
    "# The Journey from Mathematics to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e32cc0",
   "metadata": {},
   "source": [
    "## Series 1: Linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d6d6e",
   "metadata": {},
   "source": [
    "### Episode 7: Understand language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e86625",
   "metadata": {},
   "source": [
    "- NLP (Jupyter Notebook)\n",
    "    1. [Predicting IMDB Movie reviews](#1.-Predicting-IMDB-Movie-reviews)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0267a42",
   "metadata": {},
   "source": [
    "## 1. Predicting IMDB Movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaad5853-b564-4cf9-a69d-0ffbd9185234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4d14eb",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29aeaa29-9cdc-4d77-adbe-134f0be3cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/reviews.txt') as f:\n",
    "    raw_reviews = f.readlines()\n",
    "with open('dataset/labels.txt') as f:\n",
    "    raw_labels = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b86ac2-3529-4c1a-852f-f1cbaf2d87ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_reviews[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bff7fa3d-bfe1-4c14-ba82-9c16c06cad80",
   "metadata": {
    "tags": []
   },
   "source": [
    "# A few problems\n",
    "Text -> Numbers (Characters, words...)\n",
    "Length is not constant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a8cfc5-051e-49c8-ac47-eb6b4f3211b0",
   "metadata": {},
   "source": [
    "#### Creating an input vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34204eee-1a0d-48eb-a0ae-1c639bbe5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehots = {}\n",
    "onehots['goy'] = np.array([1, 0, 0, 0])\n",
    "onehots['muuhai'] = np.array([0, 1, 0, 0])\n",
    "onehots['kino'] = np.array([0, 0, 1, 0])\n",
    "onehots['baina'] = np.array([0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea75d5cf-c7eb-4d78-af1f-7d4dee2d1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['goy', 'kino', 'baina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa497a3-855e-42f3-a901-f7a2a9410537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([0, 0, 0, 0])\n",
    "for i in range(len(sentence)):\n",
    "    x += onehots[sentence[i]]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84e4072f-a8f6-4a6b-b4f8-e79694a72a97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = []\n",
    "for review in raw_reviews:\n",
    "    review = set(review.split(' '))\n",
    "    review.remove('')\n",
    "    tokens.append(list(review))\n",
    "len(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a37952f-910a-46a9-b591-a6474ce9e255",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set()\n",
    "for review in tokens:\n",
    "    for word in review:\n",
    "        words.add(word)\n",
    "words = list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aec93b5-66b9-4d57-9c46-ac0f7e2ec778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74074"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8a53383-448b-443d-9c72-b686e9e90e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {}\n",
    "for i, word in enumerate(words):\n",
    "    word_to_index[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4baca38f-ae85-4c8c-8947-8ba10949fb86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74074"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c1395a0-a947-46ba-bff8-f14efd7c4391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a3934a3-add0-4ffd-aee1-42a5b9215f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = np.zeros((len(tokens), len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "994ce255-6614-43a0-a291-bac22e6edd77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, review in enumerate(tokens):\n",
    "    for word in review:\n",
    "        input_dataset[i, word_to_index[word]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6384b4eb-3bbf-4354-95fc-41e573dcae32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dataset[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "912208e3-758c-4572-a28b-ad41d8a1ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = np.array([])\n",
    "for label in raw_labels:\n",
    "    if label == 'positive\\n':\n",
    "        target_dataset = np.append(target_dataset, 1)\n",
    "    else:\n",
    "        target_dataset = np.append(target_dataset, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d490843-516f-402e-9693-e89647def7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0eea8e89-9a96-44f2-86eb-b7b27493d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = target_dataset.reshape(25000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea146891-3fe9-4cec-a058-39a2a21fa879",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = input_dataset[:24000]\n",
    "train_labels = target_dataset[:24000]\n",
    "\n",
    "test_dataset = input_dataset[24000:]\n",
    "test_labels = target_dataset[24000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8a7c1f4-9198-4f5b-8e87-82e7e8cd3c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 74074)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a99a88",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6e74b5-5b22-4e3f-930b-8ded882e5840",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25bc4847-a10f-454b-b274-fb66fbdba1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Linear:\n",
    "    \"\"\"Representing a neural network layer\"\"\"\n",
    "    \n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        \"\"\"Initlize weights and bias\"\"\"\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_outputs)\n",
    "        self.biases = np.zeros((1, n_outputs))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        It multiplies the inputs by the weights \n",
    "        and then sums them, and then sums bias.\n",
    "        \"\"\"\n",
    "        #To calculate gradient, remembering input values\n",
    "        self.inputs = inputs\n",
    "        #Calculate outputs' values\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"Gradient with respect to parameters and input\"\"\"\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        self.dresults = np.dot(dvalues, self.weights.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17d39a0-102e-4bca-a872-44d884cfd41f",
   "metadata": {},
   "source": [
    "#### Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3286089-ddcb-4688-bac7-389cbc3371a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_ReLU:\n",
    "    \"\"\"ReLU activation\"\"\"\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        \n",
    "        #To calculate gradient, remembering input values\n",
    "        self.inputs = inputs\n",
    "        \n",
    "        #Calculate outputs' values\n",
    "        self.output = np.maximum(0, inputs)\n",
    "        \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"Backward pass\"\"\"\n",
    "        \n",
    "        self.dresults = self.inputs > 0\n",
    "        self.dresults = self.dresults * dvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "570ae286-c64d-4ced-8136-5cef2473fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Sigmoid:\n",
    "    \"\"\"Sigmoid activation\"\"\"\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        \n",
    "        #Calculate outputs' values\n",
    "        self.output = 1 / (1 + np.exp(-inputs))\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        \"\"\"Backward pass\"\"\"\n",
    "        \n",
    "        self.dresults = dvalues * (1 - self.output) * self.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe07a4b-7e7d-4e66-9155-915cc43536ee",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c05443b-dfab-40c0-807e-86e98a9addff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_MSE():\n",
    "    \"\"\"MSE Loss function\"\"\"\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"Forward pass\"\"\"     \n",
    "        error = np.mean((y_pred - y_true) ** 2)\n",
    "        return error\n",
    "    \n",
    "    def backward(self, y_pred, y_true):\n",
    "        \"\"\"Derivative of MSE with respect to preds\"\"\"\n",
    "        \n",
    "        #Number of samples\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        #Number of output nodes\n",
    "        outputs = len(y_pred[0])\n",
    "        \n",
    "        #Derivative of MSE\n",
    "        self.dresults = 2 * (y_pred - y_true) / (outputs * samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f28cdac-2be6-45ae-8244-67b01667aa66",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "010d7844-5d0d-49a0-b223-826118c4e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_GD:\n",
    "    \"\"\"Gradient descent optimizer\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=1.):\n",
    "        \"\"\"Initialize hyperparameters\"\"\"\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def update_parameters(self, layer):\n",
    "        \"\"\"Update parameters\"\"\"\n",
    "        \n",
    "        weights_delta = layer.dweights * self.alpha\n",
    "        biases_delta = layer.dbiases * self.alpha\n",
    "        \n",
    "        #Update parameters\n",
    "        layer.weights -= weights_delta\n",
    "        layer.biases -= biases_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569fabc1",
   "metadata": {},
   "source": [
    "### Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "800fd1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 10\n",
    "alpha = 0.1\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c3207d-c8cb-4f18-abb5-02ff21f78155",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e99c9752-70d2-422e-98b4-4646796cfa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Layer_Linear(len(words), 100)\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "layer2 = Layer_Linear(100, 1)\n",
    "activation2 = Activation_Sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca296f-6e61-417c-9f84-f79bfe54a4af",
   "metadata": {},
   "source": [
    "#### Initlize optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3259810-66ae-4de8-b480-3c37f5579bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Loss_MSE()\n",
    "optimizer = Optimizer_GD(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2580f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4dfd3289-17bf-4bf0-a7dc-70842648aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = len(train_dataset) // batch_size\n",
    "if train_steps * batch_size < len(train_dataset):\n",
    "    train_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e766463",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Train error: 0.249, Train accuracy: 0.586\n",
      "epoch: 1, Train error: 0.212, Train accuracy: 0.762\n",
      "epoch: 2, Train error: 0.137, Train accuracy: 0.832\n",
      "epoch: 3, Train error: 0.108, Train accuracy: 0.862\n",
      "epoch: 4, Train error: 0.094, Train accuracy: 0.878\n",
      "epoch: 5, Train error: 0.085, Train accuracy: 0.893\n",
      "epoch: 6, Train error: 0.078, Train accuracy: 0.902\n",
      "epoch: 7, Train error: 0.073, Train accuracy: 0.911\n",
      "epoch: 8, Train error: 0.068, Train accuracy: 0.917\n",
      "epoch: 9, Train error: 0.064, Train accuracy: 0.923\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    train_error = 0\n",
    "    train_accuracy = 0\n",
    "    \n",
    "    for i in range(train_steps):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = (i+1) * batch_size\n",
    "        \n",
    "        input = train_dataset[batch_start:batch_end]\n",
    "        true = train_labels[batch_start:batch_end]\n",
    "        \n",
    "        #Forward pass\n",
    "        layer1.forward(input)\n",
    "        activation1.forward(layer1.output)\n",
    "        layer2.forward(activation1.output)\n",
    "        activation2.forward(layer2.output)\n",
    "        train_error += loss.forward(activation2.output, true) / train_steps\n",
    "        train_accuracy += np.mean((np.abs(activation2.output - true) < 0.5)) / train_steps\n",
    "        \n",
    "        #Backward pass\n",
    "        loss.backward(activation2.output, true)\n",
    "        activation2.backward(loss.dresults)\n",
    "        layer2.backward(activation2.dresults)\n",
    "        activation1.backward(layer2.dresults)\n",
    "        layer1.backward(activation1.dresults)\n",
    "        \n",
    "        #Update parameters\n",
    "        optimizer.update_parameters(layer2)\n",
    "        optimizer.update_parameters(layer1)\n",
    "\n",
    "    print(f'epoch: {epoch},',\n",
    "          f'Train error: {train_error:.3f},',\n",
    "          f'Train accuracy: {train_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8d7d7e-1c28-4ae0-b41e-9806661baf1a",
   "metadata": {},
   "source": [
    "#### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9bb7fc60-52f1-477e-9b53-d69524e814d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = len(test_dataset) // batch_size\n",
    "if test_steps * batch_size < len(test_dataset):\n",
    "    test_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "083e8e8f-2651-4485-80dc-1111b9483067",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (104,1) (128,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1d/p59jqbhj46v7_0qr3yh772th0000gn/T/ipykernel_55572/2407175729.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlayer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mactivation2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtest_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtest_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtest_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/1d/p59jqbhj46v7_0qr3yh772th0000gn/T/ipykernel_55572/2432095330.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y_pred, y_true)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m\"\"\"Forward pass\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (104,1) (128,1) "
     ]
    }
   ],
   "source": [
    "test_error = 0\n",
    "test_accuracy = 0\n",
    "\n",
    "for i in range(test_steps):\n",
    "    batch_start = i * batch_size\n",
    "    batch_end = (i+1) * batch_size\n",
    "    \n",
    "    input = test_dataset[batch_start:batch_end]\n",
    "    true = test_labels[batch_start:batch_end]\n",
    "    \n",
    "    activation1.forward(layer1.output)\n",
    "    layer2.forward(activation1.output)\n",
    "    activation2.forward(layer2.output)\n",
    "    test_error += loss.forward(activation2.output, true) / test_steps\n",
    "    print(test_error)\n",
    "    test_accuracy += np.mean((np.abs(activation2.output - true) < 0.5)) / test_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4a5ede72-c0a3-4450-b2c7-f82b75900225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 0.105, Test accuracy: 0.854\n"
     ]
    }
   ],
   "source": [
    "print(f'Test error: {test_error:.3f},',\n",
    "      f'Test accuracy: {test_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d41cf-05bc-43ae-a313-b5c0e6e7cb91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
